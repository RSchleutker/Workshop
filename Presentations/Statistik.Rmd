---
title: "Statistik mit R"
author: "Raphael Schleutker und Hannah Schmitz"
date: "7. Oktober 2017"
css: style.css
output: 
  ioslides_presentation: 
    highlight: kate
    logo: ./Figures/wwu.svg
    widescreen: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	error = TRUE,
	fig.height = 3,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
```


# Nomenklatur

## Population vs. Stichprobe

Stellt euch vor, ihr möchtet herausfinden, bei welchem mittlerem Alter Patienten mit Parkinson diagnostiziert werden.

>- Sämtliche Menschen weltweit mit einer Parkinson-Diagnose stellen die Grundgesamtheit oder auch Population dar.
>- Alle Menschen, die euch für eure Studie zur Verfügung stehen, stellen die Stichprobe dar.


## Parameter vs. Statistik

>- Eigenschaften der Population, wie z.B. das mittlere Diagnose-Alter, bezeichnet man als Parameter.
>- Werte, die ihr von eurer Stichprobe berechnet, bezeichnet man als Statistik. Bei einem guten Design erlauben Statistiken Rückschlüsse auf die Parameter der zugrundeliegende Population.
>- Parameter werden mit griechischen Buchstaben abgekürzt, Statistiken mit lateinischen.
>- $\mu$ bzw. $\overline{x}$ bezeichnen das arithmetische Mittel.
>- $\sigma$ bzw. s bezeichnen die Standardabweichung.



# Deskriptive Statistik

## summarise()

`summarise()` nimmt (einen gruppierten) Datensatz und berechnet daraus zusammenfassende Werte:

>- Zentrale Tendenzen (Arithmetisches Mittel, Median, Modus).
>- Verteilungsmaße (Standardfehler, Varianz).
>- Konfidenzintervalle
>- ...

***

```{r, message=FALSE, warning=FALSE}
Diameter <- read_csv("../Exercises/Diameter/Diameter.csv")

head(Diameter)
```


## Zentrale Tendenz

Gegebenenfalls gruppiert man seine Daten und fasst diese dann zusammen.

```{r}
DiameterAnalysis <- Diameter %>%
  group_by(Species, CatID, Group) %>%
  summarise(Count = n(),
            Mean_Diameter = mean(`Length [um]`))
```


***

```{r}
head(DiameterAnalysis)
```

***

Außerdem möglich:

>- `median()`: Der Median.
>- `DescTools::Mode()`: Der häufigste Wert (sinnvoll für kategorische Werte).


## Variation

```{r}
DiameterAnalysis <- Diameter %>%
  group_by(Species, CatID, Group) %>%
  summarise(Count = n(),
            Mean_Diameter = mean(`Length [um]`),
            SD_Diameter = sd(`Length [um]`))
```

`var()` geht natürlich auch.

***

```{r}
head(DiameterAnalysis)
```


# Statistische Tests

## Doch zuvor etwas Grundsätzliches

Die Statistik sollte nicht erst **nach** einem Experiment beginnen, sondern bereits **davor**.

>- Stelle eine biologische Fragestellung auf
>- Formuliere eine biologische Nullhypothese
>- Formuliere eine statistische Nullhypothese
>- Stelle heraus, welche Variablen für das Experiment von Bedeutung sind und welchen Typus sie haben.
>- Designe das Experiment!
>- Wähle einen statistischen Test
>- Führe das Experiment durch
>- Überprüfe deine Messergebnisse
>- Führe den statistischen Test durch

***

Erst im letzten Schritt geht es darum, den statistischen Test auf seine Daten anzuwenden und die Ergebnisse zu interpretieren.

>- Ist der Befund überhaupt biologisch relevant?


## Null- und Alternativhypothese

Vor einem Test stellt man immer eine Null- und eine Alternativ-Hypothese auf (damit überhaupt klar ist, worauf man testet).

>- *H~0~*: Da man i.d.R. immer auf einen Unterschied testet, und die Null-Hypothese das Gegenteil darstellt, ist H~0~ die Hypothese, dass es keinen Unterschied zwischen zwei Gruppen gibt / zwei Variablen unabhängig voneinander sind / usw.
>- *H~A~*: Die Alternativ-Hypothese ist die gegenteilige Annahme der Null-Hypothese: Es gibt einen Unterschied zwischen zwei Gruppen oder zwei Variablen sind abhängig voneinander.
>- Der *p-Value* gibt die Wahrscheinlichkeit an, dass die Null-Hypothese zutrifft. Bei weniger als 5% verwirft man i.d.R. die Null-Hypothese und akzeptiert stattdessen die Alternativ-Hypothese.






## Den richtigen statistischen Test finden

>- Welcher Variablentyp soll getestet werden? **Nominal**, **Ordinal** oder **Metrisch**
>- Wie viele Gruppen sollen miteinander verglichen werden?
>- Sind die Beobachtungen unabhängig voneinander?
>- Falls die Variablen metrisch sind: Sind die Daten **normalverteilt**? Sind die Daten **homoskedastisch** (gleiche SD)? Sind die zu vergleichenden Gruppen **gleich groß**?



# Nominale Variablen testen

## Die Idee

Nominale Datenreihen bestehen nicht aus Zahlen, deren Mittelwert und Variation man testen kann. Stattdessen kann man nur die Häufigkeit jedes Werts mit einer erwarteten Häufigkeit vergleichen. Es wird unterschieden zwischen **Goodness-of-Fit-Tests** und **Independence-Tests**.


## Goodness-of-Fit Tests

Testen eine beobachtete Häufigkeitsverteilung mit einer hypothetischen.

>- Exact Test for Goodness-of-Fit (<1000 Beobachtungen)
>- $\chi^2$-Test (>1000 Beobachtungen)

## Zunächst muss eine Kontingenztabelle erstellt werden

```{r}
library(NHANES)

ContingencyTable <- xtabs(~ Gender, NHANES)
ContingencyTable

prop.table(ContingencyTable)
```

## Excact Binomial Test for Goodness-of-Fit

Gut geeignet für Datensätze mit weniger als 1000 Beobachtungen und nur zwei Ausprägungen.

```{r}
binom.test(ContingencyTable, p = 0.5)
```

## $\chi^2$-Test for Goodness-of-Fit

Für viele Beobachtungen und zwei oder mehr Ausprägungen.

```{r}
chisq.test(ContingencyTable, p = c(0.5, 0.5))
```

***

```{r}
ContingencyTable <- xtabs(~ Education, NHANES)
ContingencyTable
```

***

```{r}
chisq.test(ContingencyTable, p = c(0.06, 0.12, 0.21, 0.31, 0.30))
```



## Independence-Tests

Testet, ob zwei Variablen unabhängig voneiandner sind.

>- Fisher's exact Test.
>- $\chi^2$-Test for Independence.


## Kontingenztabelle erstellen

```{r}
ContingencyTable <- xtabs(~ Gender + Diabetes, NHANES)
ContingencyTable
prop.table(ContingencyTable)
```

## Independence-Test durchführen

```{r}
fisher.test(ContingencyTable)
```

***

```{r}
chisq.test(ContingencyTable)
chisq.test(ContingencyTable, correct = FALSE)
```

## Annahmen

Der $\chi^2$-Test hat zwei Annahmen an die Daten:

>- Keine Zelle darf den Wert 0 enthalten.
>- Mindestens 80% der Zellen müssen einen Wert >= 5 haben.
>- Trifft eine der Annahmen nicht zu, kann man eine Yates-Korrektur hinzufügen oder man nimmt den Fisher-Test.



## Mosaikplots

Kontingenztabellen kann man in Mosaikplots darstellen. Allerdings verlieren diese schnell ihre Übersichtlichkeit.

```{r}
ContingencyTable <- xtabs(~ Gender + Education + Diabetes, NHANES)
ContingencyTable
```

***

```{r, fig.height=5}
mosaicplot(ContingencyTable)
```

## Mosaikplots in ggplot2

Auch `ggplot2` bietet durch das Erweiterungspaket `ggmosaic` die Möglichkeit, Mosaikplots zu erstellen.

Wenn es interessiert: [ggmosaic](https://cran.r-project.org/web/packages/ggmosaic/vignettes/ggmosaic.html)


# Metrische Variablen testen

## Annahmen

Die meisten Tests für metrische Variablen sind parametrisch und stellen daher Anforderungen an die zu untersuchenden Daten:

>- Die Daten müssen **normalverteilt** sein.
>- Die Daten müssen **homoskedastisch** sein, also die gleiche Standardabweichung besitzen.
>- Die Beobachtungen müssen unabhängig voneinander sein.
>- Die zu vergleichenden Gruppen müssen gleich groß sein.


## Was tun, wenn die Daten nicht passen?

Man hat zwei Möglichkeiten, wenn die Daten den Vorgaben absolut nicht entsprechen.

>- Man wählt einen nicht-parametrischen Test.


## Der Datensatz

```{r}
head(PlantGrowth)
```



## Normalität

Durch Histogramm zu erkennen oder mit einem Test wie dem Shapiro-Wilk-Test.

* H~0~, dass die Daten normalverteilt sind.

```{r}
shapiro.test(PlantGrowth$weight)
```


## Standardfehler

Der **Standardfehler** ist ein Maß für die Streuung **zwischen** den Stichproben.

$$ \frac{\sigma}{\sqrt{n}} $$

* $\sigma$ ist die Standardabweichung der Grundgesamtheit und muss von der Stichprobe geschätzt werden ($s$).
* $n$ ist der Stichprobenumfang.


## t-Tests

t-Tests überprüfen, wie viele Standardfehler der Stichprobenmittelwert von einem Erwartungswert abweicht.

* Als Ergebnis erhält man eine sogenannte t-Statistik.

$$ t = \frac{\overline{X} - \mu}{\frac{\sigma}{\sqrt{n}}} $$


## t-Verteilung

```{r, echo=FALSE, fig.height=4}
data <- data.frame(x = seq(-5, 5, 0.001), y = dt(seq(-5, 5, 0.001), 29))
shade1 <- subset(data, x < qt(0.025, 29))
shade2 <- subset(data, x > qt(0.975, 29))

tplot <- ggplot(data, aes(x, y)) +
  geom_area(data = shade1, aes(y = y), fill = "grey") +
  geom_area(data = shade2, aes(y = y), fill = "grey") +
  geom_line() +
  scale_x_continuous(name = "Standardfehler")

tplot
```



## One-Sample t-Test

$$ \frac{\overline{X} - \mu}{\frac{\sigma}{\sqrt{n}}} $$

```{r}
(5.073 - 4.85) / (0.7012 / sqrt(30))
```

***

```{r, echo=FALSE, fig.height=4}
tplot +
  geom_vline(xintercept = 1.742)
```

***

```{r, echo=FALSE, fig.height=4}
tplot +
  stat_function(data = data.frame(x = c(-5,5)), fun = dt, args = list(df = 1),
                inherit.aes = FALSE, colour = "red")
```



***

```{r}
t.test(PlantGrowth$weight, mu = 4.85)
```


## Alternativen

Alternativ kann man testen, ob der Beobachtete Mittelwert höher oder geringer ist als der vorgegebene (einseitiger Test).

```{r}
t.test(PlantGrowth$weight, mu = 4.85, alternative = "less")
```

***

```{r}
t.test(PlantGrowth$weight, mu = 4.85, alternative = "greater")
```

***

```{r, echo=FALSE, fig.height=5}
shade3 <- subset(data, x > qt(0.95, df = 29))

ggplot(data, aes(x, y)) +
  geom_area(data = shade3, aes(y = y), fill = "red", alpha = .5) +
  geom_area(data = shade1, aes(y = y), fill = "grey") +
  geom_area(data = shade2, aes(y = y), fill = "grey") +
  geom_line() +
  geom_vline(xintercept = 1.742)
```



## Two-Sample t-Test

Häufiger möchte man eine metrische Variable zwischen zwei Gruppen miteinander vergleichen.

## Varianzgleichheit

Mithilfe des Bartlett-Tests kann man die Varianzgleichheit zweier oder mehrerer Gruppen überprüfen.

* H~0~, dass die Gruppen die gleiche Varianz haben.

```{r}
bartlett.test(weight ~ group, PlantGrowth)
```



## Der Test

Für den Two-Sample t-Test wählt man ebenfalls `t.test`, benutzt allerdings das formula-Interface der Funktion.

```{r}
t.test(weight ~ group, PlantGrowth, var.equal = TRUE,
       subset = group != "trt2")
```

## Welch Two Sample-t-Test

Sind die Varianzen in den beiden Gruppen unterschiedlichen, unbekannt oder sind die Stichprobengrößer deutlich kleiner als 30, wählt man den Welch two-sample T-Test.

```{r}
t.test(weight ~ group, PlantGrowth, var.equal = FALSE,
       subset = group != "trt2")
```


## Paired Two-Sample T-Test

Man kann für den `t.test` das Argument `paired` auch auf `TRUE` setzen. Einen gepaarten T-Test für zwei Stichproben führt man durch, wenn die Beobachtungen gepaart sind.

Dies ist z.B. der Fall, wenn man Blutwerte von Patienten vor und nach Behandlung misst und miteinander vergleicht, anstatt zwei unabhängige Patientengruppen miteinander zu vergleichen.

Hierbei muss der erste Wert in der ersten Gruppe dem ersten Wert in der zweiten Gruppe entsprechen. In unserem Beispiel müssen sie also vom gleichen Patienten stammen.

Der paired Two-Sample T-Test ist exakt das gleiche wie ein One-Sample T-Test, bei dem man die Differenzen zwischen den Paaren auf den Wert 0 testet.


## Type I und Type II Error und die Power eines Tests


Error Typen     | H~0~ ist wahr                 | H~0~ ist falsch
----------------|-------------------------------|-------------------------------
H~0~ abgelehnt  | Type I Error (False Positive); P = $\alpha$ | Korrekt (True Positive); P = 1 - $\beta$ 
H~0~ akzeptiert | Korrekt (True Negative); P = 1 - $\alpha$      | Type II Error (False Negative); P = $\beta$

>- Die Power eines Tests ist die Fähigkeit, zwischen zwei Mittelwerten zu unterscheiden, wenn tatsächlich ein Unterschied vorhanden ist.
>- Power ist definiert als $1 - \beta$.


## Effect Size

Die Effect Size gibt an, um wie viele Standardabweichungen zwei Mittelwerte voneinander abweichen.

$$ \frac{\mu_1 - \mu_2}{\sigma} $$

* $\mu_1$ und $\mu_2$ sind die Mittelwerte der Populationen und können durch die Stichproben-Mittelwerte ersetzt werden.
* $\sigma$ ist ist die Standardabweichung, welche für beide Stichrpoben glich sein sollte. Ansonsten benutzt man die gepoolte Standardabweichung.


## Power-Analyse

Hat man aus vorherigen Experimenten eine verlässliche Schätzung für die Standardabweichung, kann man berechnen, wie groß der Stichprobenumfang sein muss, um für eine gegebene Effect Size ein bestimmtes Power-Level zu erreichen.

>- Typischerweise sollte die Power eines Tests bei 80% - 90% liegen.

***

```{r}
power.t.test(n = 10, delta = 0.371, sig.level = 0.05, sd = 0.7,
             type = "two.sample", alternative = "two.sided")
```

***

```{r}
power.t.test(delta = 0.371, sig.level = 0.05, sd = 0.7, power = 0.9,
             type = "two.sample", alternative = "two.sided")
```

